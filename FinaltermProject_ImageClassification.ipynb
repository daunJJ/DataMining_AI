{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prob1: Your Best Image Classification Model"
      ],
      "metadata": {
        "id": "Hoy9y7ie7Idq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기본 모형 적합\n",
        "먼저 사전훈련된 vgg16모델을 기본 모델로 사용하였다.\\\n",
        "vgg16모델을 사용한 이유는 강의자료에 예시로 쓰였기 때문에 가장 먼저 사용하였다. \\\n",
        "설정한 파라미터는 다음과 같다.\\\n",
        "batch_size =32, learning_rate = 0.0002, num_epoch = 10 \\\n",
        "위와 같이 설정한 이유는 강의자료에서 많이 쓰이는 숫자를 이용하였고, 에폭의 수를 키울수록 학습시간이 방대하게 늘어나기 때문에 에폭은 비교적 작은 수인 10으로 설정하였다."
      ],
      "metadata": {
        "id": "2ICJu3hKXxrt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PlaRElX68Pj"
      },
      "outputs": [],
      "source": [
        "# import module\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as tr\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size =32\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ],
      "metadata": {
        "id": "k1LdAIH0kEKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "o11cXqDg7XNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./Data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./Data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F251FKn7XPp",
        "outputId": "d4a9a3a3-bc94-42f4-abd4-ff608afd3a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12965555.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./Data/cifar-10-python.tar.gz to ./Data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "aYulIaD58SdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG-16\n",
        "import torchvision.models as models\n",
        "\n",
        "vgg16_ver1 = models.vgg16(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "id": "HBCI1LdKCVhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8f5eb7-376c-49bc-8e04-67d5cfb59d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 260MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16_ver1.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp_hkmRfbGzf",
        "outputId": "e05d3339-c9f8-44e4-821f-76437212b02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10 데이터에 맞춰 모델구조 변경\n",
        "vgg16_ver1.classifier[6] = nn.Linear(in_features=4096, out_features = 10)\n",
        "vgg16_ver1.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJs80RAWCVk5",
        "outputId": "70713237-b160-448f-a7db-d17d57b3e563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = vgg16_ver1.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 1==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "taF7PJXXd8oC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3f418b-afb0-461e-dda1-5d3734a0d4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3801, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  vgg16_ver1.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = vgg16_ver1(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "id": "zaWjB_Mzd8q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e909201d-6aa1-4c6c-8f97-34a100ef5b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 87.59 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 모형에서의 Accuracy는 87.59 %를 얻었다."
      ],
      "metadata": {
        "id": "J6r28KyYnC-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도1: 학습률 0.0002 -> 0.0001로 낮추기\n",
        "일반적으로 학습률을 낮추면 모델 파라미터가 크게 업데이트 되지 않아 학습이 안정적이게 된다. \\\n",
        "또한 오버슈팅의 가능성이 낮아지므로 모델의 성능이 높아질 것이라 기대하여 학습률을 낮춰 다시 학습하였다."
      ],
      "metadata": {
        "id": "3wu4NRwTVQmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.0001  # 학습률 조정\n",
        "num_epoch = 10"
      ],
      "metadata": {
        "id": "f-jjOgD_VuM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "P2zBCzS_4not"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./Data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./Data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hCHZRiJ4nrj",
        "outputId": "d167f220-2ab9-43e4-8652-a87ee34e3792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ekzew8OH4nty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg-16\n",
        "vgg16_ver3 = models.vgg16(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "id": "qvHYAvZh4nwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16_ver3.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf5C5gyY4nyq",
        "outputId": "d8651f9d-2fba-4304-b635-b8400a3b27e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10 데이터에 맞춰 모델구조 변경\n",
        "vgg16_ver3.classifier[6] = nn.Linear(in_features=4096, out_features = 10)\n",
        "vgg16_ver3.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-wsCcFf4n1h",
        "outputId": "a517ecdb-d9a6-4920-923d-8ef03638aea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = vgg16_ver3.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 1==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aphzQOEI5ACP",
        "outputId": "986f3e87-be1e-4bcf-b0b7-6536761c61dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  vgg16_ver3.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = vgg16_ver3(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLKykaRn5AE5",
        "outputId": "12deb45d-af28-4019-ddcb-0ebac28988d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 90.57 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기대에 맞게 Accuracy가 소폭 상승하여 90.57%를 얻었다."
      ],
      "metadata": {
        "id": "eQ0clXMwudCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도2: 에폭 수 10 -> 20로 늘리기\n",
        "일반적으로 에폭 수를 늘리면 모델의 일반화 능력이 향상되고, 최적해를 찾는데 더 많은 기회를 갖게 되어 모델의 성능을 향상시킬 수 있다. \\\n",
        "따라서 에폭 수를 늘려 다시 학습하였다."
      ],
      "metadata": {
        "id": "fXZ-GcQ5Wq1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.0001\n",
        "num_epoch = 20"
      ],
      "metadata": {
        "id": "uKIC6m6pexCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "Rf3sl5OQexEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./Data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./Data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "id": "x3wfwkrIexJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7060177-aa16-477c-eb64-045ac50a5e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12681599.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./Data/cifar-10-python.tar.gz to ./Data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "k42Bd7rlexMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "OZdmp1TXl0Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg-16\n",
        "vgg16_ver4 = models.vgg16(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "id": "_4lCC6xsexOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cced4acb-233c-47c0-b614-09199b07a226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 87.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "RjY7vroCexQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14deedc0-1214-4bf5-b059-cd422013cc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10 데이터에 맞춰 모델구조 변경\n",
        "vgg16_ver4.classifier[6] = nn.Linear(in_features=4096, out_features = 10)\n",
        "vgg16_ver4.to(\"cuda:0\")"
      ],
      "metadata": {
        "id": "K9qKztGoexUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d9a8e3-6d7b-44a9-eaed-8eedc50780a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = vgg16_ver4.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 1==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "id": "l-Fkadq6WmxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217adda8-7936-4712-e0c6-8b948e56a1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  vgg16_ver4.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = vgg16_ver4(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "id": "YFeWm7OmfpKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5089c3fc-e262-406e-e6d6-53c17b0ed842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 89.61 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기대와 달리 모델의 Accuracy가 하락하여 89.61%를 얻었다."
      ],
      "metadata": {
        "id": "qZ7r7WUn7Jgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도3: 옵티마이저 변경 Adam -> SGD\n",
        "옵티마이저도 모델의 성능에 영향을 끼치기 때문에, Adam 옵티마이저가 아닌 SGD 옵티마이저를 사용하여 모델의 성능을 비교해보고자 하였다."
      ],
      "metadata": {
        "id": "M3Ul0B9aXD-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.0001\n",
        "num_epoch = 10  # 에폭 수 다시 원래대로"
      ],
      "metadata": {
        "id": "cnZiZ7e-d8vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "vSu_KyjIFEQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./Data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./Data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP5Hs00MFESb",
        "outputId": "a9e5f6f7-ee90-4bec-ed1e-a315d754943b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29352798.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./Data/cifar-10-python.tar.gz to ./Data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "AkeY1EhiFEVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "dDlJTHNbFEXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg-16\n",
        "vgg16_ver5 = models.vgg16(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgqExoDvFEaX",
        "outputId": "ae241d0c-5bd3-4fdf-955d-82822fa081a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 235MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "# 옵티마이저: Adam -> SGD\n",
        "optimizer = torch.optim.SGD(vgg16_ver5.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLvOts83FEdC",
        "outputId": "4027a3d7-a1b6-4290-83ed-ce2286b6c8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10 데이터에 맞춰 모델구조 변경\n",
        "vgg16_ver5.classifier[6] = nn.Linear(in_features=4096, out_features = 10)\n",
        "vgg16_ver5.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTz9tpGVFzUa",
        "outputId": "7331a16a-f388-41b3-b0e6-8cf2b6f7264d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = vgg16_ver5.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 1==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLxtPHikFzgq",
        "outputId": "41acd6f1-2f8e-436f-b4c6-cc491edbc272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.1334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.8532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5418, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  vgg16_ver5.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = vgg16_ver5(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFqQyQGsFEg1",
        "outputId": "1f0515cb-3a24-43be-9662-bd744397a944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 83.44 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam 옵티마이저를 썼을 때와 비교하여 SGD 옵티마이저를 썼을 때 Accuracy가 83.44%로 하락하였다."
      ],
      "metadata": {
        "id": "B8ZTYqQX7cER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도4: GoogLeNet 사용하기\n",
        "다른 모델이 vgg16 모델보다 더 높은 성능을 내는지 비교해보고자 GoogLeNet 모델을 사용하였다.\\\n",
        "추가로 위에서 epoch를 20으로 할 때 10보다 성능이 낮았지만, 별 차이가 나지 않아 epoch를 15로 설정하였다. \\\n",
        "옵티마이저는 성능이 좋았던 Adam 옵티마이저를 사용하였다."
      ],
      "metadata": {
        "id": "tLA-IjU4ixFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.0001\n",
        "num_epoch = 15"
      ],
      "metadata": {
        "id": "YRiPEClVFEjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "R4k-XVWsi1dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./Data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./Data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T46gDNuHi1gx",
        "outputId": "439bdd88-49b0-4def-f1fb-9aae4f783a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 44353581.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./Data/cifar-10-python.tar.gz to ./Data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "yJk5aXRMjC5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "b5981B-scHBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogleNet\n",
        "GoolgleNet_ver6 = models.googlenet(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "id": "-sODfVS-jC8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c93760f-de49-40a3-d6d8-857961e4e145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 214MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(GoolgleNet_ver6.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKJc_pHRjC-L",
        "outputId": "2d248df9-6010-40b0-9387-f165a022b2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GoolgleNet_ver6.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqaWThA8jDEb",
        "outputId": "bce9a04a-04ac-4994-dabc-10bb746af3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): BasicConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): BasicConv2d(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): BasicConv2d(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (aux1): None\n",
              "  (aux2): None\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = GoolgleNet_ver6.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 1==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR8NSWeji1jW",
        "outputId": "56a6ee17-8ec2-4843-d88a-cb24cfc14b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  GoolgleNet_ver6.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = GoolgleNet_ver6(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "id": "Rn065005i1n1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91354e1b-ddbf-4e89-f4fb-0acfc9367be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 93.87 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogLeNet모델의 Accuracy는 93.87%로 vgg16모델보다 상승하였다."
      ],
      "metadata": {
        "id": "-M-VV-YF8Mdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도 5: 배치사이즈 32 -> 64로 늘리기\n",
        "배치사이즈는 학습 과정에서 한번에 처리하는 데이터의 수로, 배치사이즈가 크면 그래디언트 추정이 안정적이다.\\\n",
        "따라서 모델의 성능이 높아질 것이라 예상하여 배치사이즈를 늘려 모델을 다시 학습하였다."
      ],
      "metadata": {
        "id": "ROyWWaDgDB3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "num_epoch = 15"
      ],
      "metadata": {
        "id": "nShEk_2LCVoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "fI51lmZgDQSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./Data', train=True, download=True, transform=transf)\n",
        "testset = torchvision.datasets.CIFAR10(root='./Data', train=False, download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYazTbjjDQVM",
        "outputId": "5089a266-7bc9-416a-de4f-2ef5b604de0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "nke6KU1zDkr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "YnRX2iQHDkul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GoogleNet\n",
        "GoolgleNet_ver7 = models.googlenet(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "id": "7pgc7RhNDQX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(GoolgleNet_ver7.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLjqlUiuDQey",
        "outputId": "a765d2ad-631d-4f9a-ea5b-262a9e1108c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GoolgleNet_ver7.to(\"cuda:0\")"
      ],
      "metadata": {
        "id": "UWX7rdrrCVqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30845867-ab6f-496d-86fb-a6ac059068e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): BasicConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): BasicConv2d(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): BasicConv2d(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (aux1): None\n",
              "  (aux2): None\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = GoolgleNet_ver7.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 1==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sds9T8knDzpK",
        "outputId": "1333e2ad-c672-4ddd-8e35-a1f76282e4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  GoolgleNet_ver7.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = GoolgleNet_ver7(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj-H26t-Dzta",
        "outputId": "2ba9ab5d-06d8-434b-a7ef-6c8bbdddd825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 94.16 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 Accuracy가 94.16%로 소폭 상승하였다. \\\n",
        "따라서 최종 모형으로 성능이 94.16%인 시도5(GoogLeNet) 모형을 택하였다."
      ],
      "metadata": {
        "id": "COpYW_NkEATw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시도5(GoogLeNet) 모형 다운로드 받기\n",
        "torch.save(GoolgleNet_ver7, './2016400_정다운.pt')"
      ],
      "metadata": {
        "id": "SmG8-D3MFEk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모형 다운로드 받기\n",
        "torch.save(model, './정다운.pt')"
      ],
      "metadata": {
        "id": "nvz4AGNxiyQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prob2: Image Classification with the New Dataset"
      ],
      "metadata": {
        "id": "34N7flWm7PmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 기본 모형 적합\n",
        "먼저 Resnet을 기본 모델로 사용하였다.\\\n",
        "Resnet을 기본 모델로 사용한 이유는 CNN 모델 중 성능이 잘 나오는 편이라고 알고 있기 때문이다. \\\n",
        "설정한 파라미터는 다음과 같다.\\\n",
        "batch_size =64, learning_rate = 0.001, num_epoch = 100 \\\n",
        "위와 같이 설정한 이유는 강의자료에서 많이 쓰이는 숫자를 이용하였고, 사전학습된 모델보다 학습 속도가 빠른 만큼 에폭 수도 100으로 설정하였다. \\\n",
        "transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25])은 정규화를 하는 것이 성능에 좋을 것이라 판단하여 추가하였다. \\\n",
        "BasicBlock과 Resnet 구현 과정에서 채널 수나 블록 수 등은 모두 GPU 사용량을 고려하여 시도와 실패를 반복해가며 적절한 수로 설정하였다. \\\n",
        "활성화 함수로 ReLu함수를 사용한 이유는 활성화 함수 중 성능이 좋다고 알려져 있기 때문이다."
      ],
      "metadata": {
        "id": "bFHVaILw0YI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epoch = 100"
      ],
      "metadata": {
        "id": "wFaJhrWW7Wls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
        "])"
      ],
      "metadata": {
        "id": "CT9XKInAZjp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.STL10(root='./Data', split='train', download=True, transform=transf)\n",
        "testset = torchvision.datasets.STL10(root='./Data', split='test', download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qLzqvvsZkHZ",
        "outputId": "d66eb77a-914b-486c-f0b4-21187c1cafe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./Data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [02:44<00:00, 16066587.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./Data/stl10_binary.tar.gz to ./Data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "rtLj0z5KZnZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델 만들기\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
        "                           stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                           stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(planes)\n",
        "          )\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "K9oMiizwZoqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, num_classes=10, num_blocks=2):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 16\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3,\n",
        "                           stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.layer1 = self._make_layer(16, num_blocks, stride=1)\n",
        "    self.layer2 = self._make_layer(32, num_blocks, stride=2)\n",
        "    self.layer3 = self._make_layer(64, num_blocks, stride=2)\n",
        "    self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "  def _make_layer(self, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1]* (num_blocks-1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(BasicBlock(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = F.avg_pool2d(out,8)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "T_dO1X2mZqHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model_ver1 = ResNet().to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_ver1.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOUQW19XZrbh",
        "outputId": "3de0fb58-d36a-466b-d736-50418a402eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STL10 데이터에 맞춰 모델구조 변경\n",
        "model_ver1.linear = nn.Linear(3136, 10)\n",
        "model_ver1.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q25FpohwZuUv",
        "outputId": "dabadee0-966c-4122-8b51-07584a942f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=3136, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model_ver1.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 5==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkU3SSJ3ZvZ4",
        "outputId": "56a567e4-fa06-4017-a7a8-18e26ed420ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  model_ver1.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = model_ver1(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8jDZyG2ZyNq",
        "outputId": "d0035693-2d74-45a1-bb8d-dab93dd25fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 63.34 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 모형의 Accuracy는 63.34%로 사전학습된 모델에 비해 성능이 좋지 않다."
      ],
      "metadata": {
        "id": "AkovWa4v1Waq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도1: transforms.Resize의 크기를 256 -> 160로 변경\n",
        "STL10 데이터셋은 96x96으로 작은 크기를 가지므로, 256x256으로 확대하는 것보다 160x160으로 좀 더 작게 확대하는 것이 정보의 손실을 줄일 것이라 예측하여 Resize의 크기를 변경하였다.\n"
      ],
      "metadata": {
        "id": "CHDKHKWS--Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epoch = 100"
      ],
      "metadata": {
        "id": "93uvkp3h-9aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(160),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
        "])"
      ],
      "metadata": {
        "id": "jY0whcMC4L3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.STL10(root='./Data', split='train', download=True, transform=transf)\n",
        "testset = torchvision.datasets.STL10(root='./Data', split='test', download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26C7Z1ikAr3j",
        "outputId": "33a1d8ab-be01-42cc-e905-0935619a7f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "1_k8R-klAvqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model_ver2 = ResNet().to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_ver2.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TWwFWwXAvtN",
        "outputId": "39b14d3a-4fe1-40ab-91be-6b099005c451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STL10 데이터에 맞춰 모델구조 변경\n",
        "model_ver2.linear = nn.Linear(3136, 10)\n",
        "model_ver2.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yypZV1ILAvvz",
        "outputId": "f38fb9e0-b09c-48f4-9450-88707a82e17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=3136, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model_ver2.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 5==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJQulf5PAvyq",
        "outputId": "0eda2db1-b051-44f3-950d-110a1c662c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.1016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  model_ver2.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = model_ver2(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAC-GJzJBBPt",
        "outputId": "735a917c-2c84-4e6b-807f-e4afb0566ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 63.91 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "변경 전과 큰 차이는 없지만, Accuracy가 63.91%로 소폭 상승한 결과를 보인다."
      ],
      "metadata": {
        "id": "0YZWsVMM2owX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도2: 합성곱 층 1개 추가 (총 2개의 합성곱 층)\n",
        "합성곱 층을 추가하여 모델이 깊어지면 성능이 높아질 것으로 예상하여 합성곱 층을 추가하였다. \\\n",
        "합성곱 층의 채널 수와 커널 사이즈 등은 모두 경험적으로 선택하였다.\\\n",
        "활성화함수로는 위와 같은 이유로 ReLu함수를 사용하였다."
      ],
      "metadata": {
        "id": "aAKY6VLmZ6ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epoch = 100"
      ],
      "metadata": {
        "id": "ZuWP5d2hKCSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(160),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
        "])"
      ],
      "metadata": {
        "id": "CqwiECSgKCYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.STL10(root='./Data', split='train', download=True, transform=transf)\n",
        "testset = torchvision.datasets.STL10(root='./Data', split='test', download=True, transform=transf)"
      ],
      "metadata": {
        "id": "tdx6kWNYKCbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb976e3-0448-4c45-91aa-45437283f290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./Data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [02:47<00:00, 15761752.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./Data/stl10_binary.tar.gz to ./Data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "1SxGe-4KKCel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델 만들기\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
        "                           stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                           stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(planes)\n",
        "          )\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "RHfLBPNpKW2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, num_classes=10, num_blocks=2):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 16\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3,\n",
        "                           stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.layer1 = self._make_layer(16, num_blocks, stride=1)\n",
        "    self.layer2 = self._make_layer(32, num_blocks, stride=2)\n",
        "    self.layer3 = self._make_layer(64, num_blocks, stride=2)\n",
        "    self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)  # 새로운 합성곱 층 추가\n",
        "    self.bn2 = nn.BatchNorm2d(128)  # 배치 정규화 추가\n",
        "    self.linear = nn.Linear(128, num_classes)\n",
        "\n",
        "  def _make_layer(self, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1]* (num_blocks-1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(BasicBlock(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = F.relu(self.bn2(self.conv2(out)))  # 활성화함수 추가\n",
        "    out = F.avg_pool2d(out,8)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "o2tFS6g6KW-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model_ver3 = ResNet().to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_ver3.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlM6xdTDZ8MY",
        "outputId": "74245349-8442-4427-f299-40a472ba803c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STL10 데이터에 맞춰 모델구조 변경\n",
        "model_ver3.linear = nn.Linear(6272, 10)\n",
        "model_ver3.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAt9ZOysZ9Rc",
        "outputId": "24fe9f37-68fe-4ad1-f923-063b8e786e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear): Linear(in_features=6272, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model_ver3.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 5==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcj34Vj6Z-QA",
        "outputId": "fe3a71e4-98af-4f20-8f03-00fc52a55153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.1285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  model_ver3.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = model_ver3(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1k0RKzwZ_xl",
        "outputId": "211e701b-8a39-4c88-b8a0-c3edd30c1bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 72.79 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 층을 추가하여, Accuracy가 72.79%로 크게 상승하였다."
      ],
      "metadata": {
        "id": "nin1Dv7b3WPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시도3: 합성곱 2개 추가 (총 3개의 합성곱 층)\n",
        "합성곱 층의 개수를 추가한 것이 효과가 좋아 합성곱 층을 한 개 더 추가하여 총 3개의 합성곱 층의 적합을 시도하였다. \\\n",
        "합성곱 층의 채널 수나 커널 사이즈, 활성화 함수의 선택은 시도2와 같은 이유로 선택하였다."
      ],
      "metadata": {
        "id": "GqXZ3Au6geGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epoch = 100"
      ],
      "metadata": {
        "id": "Zq1EHokgi0Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "# 이미지 크기 변환 후 텐서로 변환하는 전처리\n",
        "transf = transforms.Compose([\n",
        "    transforms.Resize(160),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
        "])"
      ],
      "metadata": {
        "id": "DFT2PDWImL26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "trainset = torchvision.datasets.STL10(root='./Data', split='train', download=True, transform=transf)\n",
        "testset = torchvision.datasets.STL10(root='./Data', split='test', download=True, transform=transf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS8h65ydmMTX",
        "outputId": "85fca5af-df60-4128-c191-50d322ba0588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "gHZ9XevImPbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델 만들기\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
        "                           stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                           stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(planes)\n",
        "          )\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "iKjSaQnVgm9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, num_classes=10, num_blocks=2):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 16\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3,\n",
        "                           stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.layer1 = self._make_layer(16, num_blocks, stride=1)\n",
        "    self.layer2 = self._make_layer(32, num_blocks, stride=2)\n",
        "    self.layer3 = self._make_layer(64, num_blocks, stride=2)\n",
        "    self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)  # 새로운 합성곱 층 추가\n",
        "    self.bn2 = nn.BatchNorm2d(128)  # 배치정규화 추가\n",
        "    self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)  # 새로운 합성곱 층 추가\n",
        "    self.bn3 = nn.BatchNorm2d(256)  # 배치정규화 추가\n",
        "    self.linear = nn.Linear(256, num_classes)\n",
        "\n",
        "  def _make_layer(self, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1]* (num_blocks-1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(BasicBlock(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = F.relu(self.bn2(self.conv2(out)))  # 활성화함수 추가\n",
        "    out = F.relu(self.bn3(self.conv3(out)))  # 활성화함수 추가\n",
        "    out = F.avg_pool2d(out,8)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "HLhbWD1-gm_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model_ver4 = ResNet().to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_ver4.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSipR3IJgnCr",
        "outputId": "0e5ebde9-5dbe-466e-8833-017acef9b020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STL10 데이터에 맞춰 모델구조 변경\n",
        "model_ver4.linear = nn.Linear(12544, 10)\n",
        "model_ver4.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76lDuQDjgnFd",
        "outputId": "c8e34445-80c3-43d8-a8e3-af353406e4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear): Linear(in_features=12544, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "  for j, [image, label] in enumerate(trainloader):\n",
        "    x = image.to(device)\n",
        "    y_ = label.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model_ver4.forward(x)\n",
        "    loss = loss_func(output, y_)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if i % 5==0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baP_PyRLhNhH",
        "outputId": "dc9ccb4f-92b0-4f21-93aa-c382debe0c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  model_ver4.eval()\n",
        "  for data in testloader:\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "    outputs = model_ver4(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Test accuracy: %.2f %%'%(100*correct/total))"
      ],
      "metadata": {
        "id": "z0hun6I6gnIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb11bf14-18a2-4788-8817-519bac89cc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 74.64 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 층을 1개 더 추가(총 3개의 합성곱)하여 74.64%의 Accuracy를 얻었다.\n",
        "이를 최종 모형으로 선택한다."
      ],
      "metadata": {
        "id": "Lcwf7_h34S2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 모델"
      ],
      "metadata": {
        "id": "Vt5eJthO9lLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prob1의 최종 모델 성능\n",
        "최종성능 94.16%로 시도5의 GoolgleNet_ver7(GoogLeNet모델)에서 가장 높은 성능을 보였다. \\\n",
        "(GoogLeNet모델 이름 지정 과정에서 오타가 있어 GoolgleNet_ver7로 저장되었습니다. 유의해주시면 감사하겠습니다.)"
      ],
      "metadata": {
        "id": "Ktjev15y9sDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prob2의 최종 모델 성능\n",
        "최종 성능 74.64%로 시도3의 model_ver4(총 3개의 합성곱 층)에서 가장 높은 성능을 보였다."
      ],
      "metadata": {
        "id": "mDcWnXlW9x6E"
      }
    }
  ]
}